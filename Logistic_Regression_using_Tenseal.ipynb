{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyRHRDF5CEiBqmppOAOAwT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Siya-9/Homomorphic-Encryption/blob/main/Logistic_Regression_using_Tenseal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9kCiddi7zJo",
        "outputId": "00e7ee35-adb9-44ba-b532-b5d1d67211b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tenseal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jz6IQu687R4",
        "outputId": "76d61f5a-996c-4b05-b259-3b960e101645"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tenseal\n",
            "  Downloading tenseal-0.3.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenseal\n",
            "Successfully installed tenseal-0.3.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tenseal as ts\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from time import time\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "c0x1KWIb8-wa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/datasets/bank.csv\")\n",
        "# drop rows with missing values\n",
        "data = data.dropna()\n",
        "data = data[:-5000]\n",
        "# drop some features\n",
        "data = data.drop(columns=[\"CustomerId\", \"Geography\"])\n",
        "y = data['Exited'].values\n",
        "data = data.drop(columns=[\"Exited\"])\n",
        "X = data.values\n",
        "\n",
        "print(type(X), type(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v08ctW6q9GjN",
        "outputId": "499634c5-69bf-477e-c4cd-641c04dbfbc6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples, n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=124)\n",
        "\n",
        "# scale\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)"
      ],
      "metadata": {
        "id": "gIr1QwhU9PLy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LRModel(torch.nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(LRModel, self).__init__()\n",
        "        self.linear = torch.nn.Linear(n_input_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "model = LRModel(n_features)"
      ],
      "metadata": {
        "id": "2h3CDrUI9k8q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 300\n",
        "learning_rate = 0.01\n",
        "criterion = torch.nn.BCELoss()\n",
        "optim = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "IGHNZA7m95Qs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_pred = model(X_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "\n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    # zero grad before new step\n",
        "    optim.zero_grad()\n"
      ],
      "metadata": {
        "id": "i8fPg89U969v"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    y_predicted = model(X_test)\n",
        "    y_predicted_cls = y_predicted.round()\n",
        "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
        "    print(f'accuracy: {acc.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8A2sL5-g99nK",
        "outputId": "81a51c02-e565-496e-c944-1e6a5fbff537"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.7760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncryptedLR:\n",
        "\n",
        "    def __init__(self, torch_lr):\n",
        "        # TenSEAL processes lists and not torch tensors, so we take out the parameters from the PyTorch model\n",
        "        self.weight = torch_lr.linear.weight.data.tolist()[0]\n",
        "        self.bias = torch_lr.linear.bias.data.tolist()\n",
        "\n",
        "    def forward(self, enc_x):\n",
        "        enc_out = enc_x.dot(self.weight) + self.bias\n",
        "        return enc_out\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)\n",
        "\n",
        "\n",
        "    def encrypt(self, context):\n",
        "        self.weight = ts.ckks_vector(context, self.weight)\n",
        "        self.bias = ts.ckks_vector(context, self.bias)\n",
        "\n",
        "    def decrypt(self, context):\n",
        "        self.weight = self.weight.decrypt()\n",
        "        self.bias = self.bias.decrypt()\n",
        "\n",
        "\n",
        "eelr = EncryptedLR(model)"
      ],
      "metadata": {
        "id": "0ov0GpDO9_Ia"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "poly_mod_degree = 4096\n",
        "coeff_mod_bit_sizes = [40, 20, 40]\n",
        "# create TenSEALContext\n",
        "ctx_eval = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
        "# scale of ciphertext to use\n",
        "ctx_eval.global_scale = 2 ** 20\n",
        "# this key is needed for doing dot-product operations\n",
        "ctx_eval.generate_galois_keys()"
      ],
      "metadata": {
        "id": "-qYgURIy-ir4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_start = time()\n",
        "enc_x_test = [ts.ckks_vector(ctx_eval, x.tolist()) for x in X_test]\n",
        "t_end = time()\n",
        "print(f\"Encryption of the test-set took {int(t_end - t_start)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDsYUmyq-kRa",
        "outputId": "ca181b52-c66c-46c0-b62f-9a421df5dd57"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encryption of the test-set took 5 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encrypted_evaluation(model, enc_x_test, y_test):\n",
        "    t_start = time()\n",
        "\n",
        "    correct = 0\n",
        "    for enc_x, y in zip(enc_x_test, y_test):\n",
        "        # encrypted evaluation\n",
        "        enc_out = model(enc_x)\n",
        "        # plain comparison\n",
        "        out = enc_out.decrypt()\n",
        "        out = torch.tensor(out)\n",
        "        out = torch.sigmoid(out)\n",
        "        if torch.abs(out - y) < 0.5:\n",
        "            correct += 1\n",
        "\n",
        "    t_end = time()\n",
        "    print(f\"Evaluated test_set of {len(X)} entries in {int(t_end - t_start)} seconds\")\n",
        "    print(f\"Accuracy: {correct}/{len(X_test)} = {correct / len(X_test)}\")\n",
        "    return correct / len(X_test)\n",
        "\n",
        "\n",
        "encrypted_accuracy = encrypted_evaluation(eelr, enc_x_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWGr3piS-lwT",
        "outputId": "d5951e16-1b39-4cfe-97e8-5eabb7d3e364"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated test_set of 5000 entries in 9 seconds\n",
            "Accuracy: 1158/1500 = 0.772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncryptedLR:\n",
        "\n",
        "    def __init__(self, torch_lr):\n",
        "        self.weight = torch_lr.linear.weight.data.tolist()[0]\n",
        "        self.bias = torch_lr.linear.bias.data.tolist()\n",
        "        # we accumulate gradients and counts the number of iterations\n",
        "        self._delta_w = 0\n",
        "        self._delta_b = 0\n",
        "        self._count = 0\n",
        "\n",
        "    def forward(self, enc_x):\n",
        "        enc_out = enc_x.dot(self.weight) + self.bias\n",
        "        enc_out = EncryptedLR.sigmoid(enc_out)\n",
        "        return enc_out\n",
        "\n",
        "    def backward(self, enc_x, enc_out, enc_y):\n",
        "        out_minus_y = (enc_out - enc_y)\n",
        "        self._delta_w += enc_x * out_minus_y\n",
        "        self._delta_b += out_minus_y\n",
        "        self._count += 1\n",
        "\n",
        "    def update_parameters(self):\n",
        "        if self._count == 0:\n",
        "            raise RuntimeError(\"You should at least run one forward iteration\")\n",
        "        # update weights\n",
        "        # We use a small regularization term to keep the output\n",
        "        # of the linear layer in the range of the sigmoid approximation\n",
        "        self.weight -= self._delta_w * (1 / self._count) + self.weight * 0.01\n",
        "        self.bias -= self._delta_b * (1 / self._count)\n",
        "        # reset gradient accumulators and iterations count\n",
        "        self._delta_w = 0\n",
        "        self._delta_b = 0\n",
        "        self._count = 0\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(enc_x):\n",
        "        # We use the polynomial approximation of degree 3 sigmoid(x) = 0.5 + 0.197 * x - 0.004 * x^3 which fits the function pretty well in the range [-5,5]\n",
        "        return enc_x.polyval([0.5, 0.197, 0, -0.004])\n",
        "\n",
        "    def plain_accuracy(self, x_test, y_test):\n",
        "        # evaluate accuracy of the model on the plain (x_test, y_test) dataset\n",
        "        w = torch.tensor(self.weight)\n",
        "        b = torch.tensor(self.bias)\n",
        "        out = torch.sigmoid(x_test.matmul(w) + b).reshape(-1, 1)\n",
        "        correct = torch.abs(y_test - out) < 0.5\n",
        "        return correct.float().mean()\n",
        "\n",
        "    def encrypt(self, context):\n",
        "        self.weight = ts.ckks_vector(context, self.weight)\n",
        "        self.bias = ts.ckks_vector(context, self.bias)\n",
        "\n",
        "    def decrypt(self):\n",
        "        self.weight = self.weight.decrypt()\n",
        "        self.bias = self.bias.decrypt()\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)\n"
      ],
      "metadata": {
        "id": "-3CU5BPr-n5H"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "poly_mod_degree = 8192\n",
        "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
        "# create TenSEALContext\n",
        "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
        "ctx_training.global_scale = 2 ** 21\n",
        "ctx_training.generate_galois_keys()"
      ],
      "metadata": {
        "id": "htujPnvv_LAA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_start = time()\n",
        "enc_x_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in X_train]\n",
        "enc_y_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_train]\n",
        "t_end = time()\n",
        "print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ5INHvV_MVE",
        "outputId": "705354ea-a5fb-4182-e8cf-62c3d90beab1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encryption of the training_set took 100 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eelr = EncryptedLR(LRModel(n_features))\n",
        "accuracy = eelr.plain_accuracy(X_test, y_test)\n",
        "print(f\"Accuracy at epoch #0 is {accuracy}\")\n",
        "\n",
        "times = []\n",
        "for epoch in range(5):\n",
        "    eelr.encrypt(ctx_training)\n",
        "    t_start = time()\n",
        "    for enc_x, enc_y in zip(enc_x_train, enc_y_train):\n",
        "        enc_out = eelr.forward(enc_x)\n",
        "        eelr.backward(enc_x, enc_out, enc_y)\n",
        "    eelr.update_parameters()\n",
        "    t_end = time()\n",
        "    times.append(t_end - t_start)\n",
        "\n",
        "    eelr.decrypt()\n",
        "    accuracy = eelr.plain_accuracy(X_test, y_test)\n",
        "    print(f\"Accuracy at epoch #{epoch + 1} is {accuracy}\")\n",
        "\n",
        "\n",
        "\n",
        "print(f\"\\nAverage time per epoch: {int(sum(times) / len(times))} seconds\")\n",
        "print(f\"Final accuracy is {accuracy}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4ZC4snE_OMP",
        "outputId": "a03ef26e-25a2-448a-ee90-5ed1106947a9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy at epoch #0 is 0.4713333249092102\n",
            "Accuracy at epoch #1 is 0.7506666779518127\n",
            "Accuracy at epoch #2 is 0.7866666913032532\n",
            "Accuracy at epoch #3 is 0.7900000214576721\n",
            "Accuracy at epoch #4 is 0.7826666831970215\n",
            "Accuracy at epoch #5 is 0.7820000052452087\n",
            "\n",
            "Average time per epoch: 479 seconds\n",
            "Final accuracy is 0.7820000052452087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diff_accuracy = acc - accuracy\n",
        "print(f\"Difference between plain and encrypted accuracies: {diff_accuracy}\")\n",
        "if diff_accuracy < 0:\n",
        "    print(\"Accuracy is greater when trained on encrypted data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_kmx67K_QYa",
        "outputId": "84b54988-5953-4104-e8df-65e87be0803f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference between plain and encrypted accuracies: -0.0059999823570251465\n",
            "Accuracy is greater when trained on encrypted data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rmv9MUgcLtgG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}