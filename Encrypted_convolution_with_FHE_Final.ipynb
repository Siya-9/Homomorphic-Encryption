{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/Siya-9/Homomorphic-Encryption/blob/main/Encrypted_convolution_with_FHE.ipynb",
      "authorship_tag": "ABX9TyMkbqU+CFYXos64EpNdX4Zk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Siya-9/Homomorphic-Encryption/blob/main/Encrypted_convolution_with_FHE_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(73)\n",
        "\n",
        "train_data = datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_data = datasets.MNIST('data', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "mw7R_q4MacY4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining below a NN"
      ],
      "metadata": {
        "id": "jm33JWMmDCJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(torch.nn.Module):\n",
        "    def __init__(self, hidden=64, output=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(1, 4, kernel_size=7, padding=0, stride=3)\n",
        "        self.fc1 = torch.nn.Linear(256, hidden)\n",
        "        self.fc2 = torch.nn.Linear(hidden, output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        # the model uses the square activation function\n",
        "        x = x * x\n",
        "        # flattening while keeping the batch axis\n",
        "        x = x.view(-1, 256)\n",
        "        x = self.fc1(x)\n",
        "        x = x * x\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "ir_Ay0Zdac_8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, criterion, optimizer, n_epochs=10):\n",
        "    # model in training mode\n",
        "    model.train()\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "\n",
        "        train_loss = 0.0\n",
        "        for data, target in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # calculate average losses\n",
        "        train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
        "\n",
        "    # model in evaluation mode\n",
        "    model.eval()\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "dJ2nzoXCcHFr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNet()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "model = train(model, train_loader, criterion, optimizer, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7Hu-ZN6cJJy",
        "outputId": "1b3d1e6a-a969-4e83-e926-b0c0f653ed38"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.397561\n",
            "Epoch: 2 \tTraining Loss: 0.130699\n",
            "Epoch: 3 \tTraining Loss: 0.088399\n",
            "Epoch: 4 \tTraining Loss: 0.071318\n",
            "Epoch: 5 \tTraining Loss: 0.058989\n",
            "Epoch: 6 \tTraining Loss: 0.050542\n",
            "Epoch: 7 \tTraining Loss: 0.044438\n",
            "Epoch: 8 \tTraining Loss: 0.038261\n",
            "Epoch: 9 \tTraining Loss: 0.034641\n",
            "Epoch: 10 \tTraining Loss: 0.030696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above operation takes 2 mins."
      ],
      "metadata": {
        "id": "Nm68FB8vKXww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_loader, criterion):\n",
        "    # initialize lists to monitor test loss and accuracy\n",
        "    test_loss = 0.0\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "\n",
        "    # model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    for data, target in test_loader:\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        test_loss += loss.item()\n",
        "        # convert output probabilities to predicted class\n",
        "        _, pred = torch.max(output, 1)\n",
        "        # compare predictions to true label\n",
        "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "        # calculate test accuracy for each object class\n",
        "        for i in range(len(target)):\n",
        "            label = target.data[i]\n",
        "            class_correct[label] += correct[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "    # calculate and print avg test loss\n",
        "    test_loss = test_loss/len(test_loader)\n",
        "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
        "\n",
        "    for label in range(10):\n",
        "        print(\n",
        "            f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n",
        "            f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'\n",
        "        )\n",
        "\n",
        "    print(\n",
        "        f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% '\n",
        "        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n",
        "    )\n",
        "\n",
        "test(model, test_loader, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcd9qbNGdXK4",
        "outputId": "085b5abd-7a5a-4dfb-8ea2-cae3c21a58d2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.088565\n",
            "\n",
            "Test Accuracy of 0: 98% (966/980)\n",
            "Test Accuracy of 1: 99% (1130/1135)\n",
            "Test Accuracy of 2: 98% (1015/1032)\n",
            "Test Accuracy of 3: 99% (1002/1010)\n",
            "Test Accuracy of 4: 98% (967/982)\n",
            "Test Accuracy of 5: 98% (878/892)\n",
            "Test Accuracy of 6: 98% (944/958)\n",
            "Test Accuracy of 7: 98% (1011/1028)\n",
            "Test Accuracy of 8: 96% (941/974)\n",
            "Test Accuracy of 9: 96% (969/1009)\n",
            "\n",
            "Test Accuracy (Overall): 98% (9823/10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tenseal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J5VEl8fdrlm",
        "outputId": "fc106bb4-1e14-4c7e-dfa2-73b8a41c6cc3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tenseal\n",
            "  Downloading tenseal-0.3.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenseal\n",
            "Successfully installed tenseal-0.3.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tenseal as ts\n",
        "\n",
        "\n",
        "class EncConvNet:\n",
        "    def __init__(self, torch_nn):\n",
        "        self.conv1_weight = torch_nn.conv1.weight.data.view(\n",
        "            torch_nn.conv1.out_channels, torch_nn.conv1.kernel_size[0],\n",
        "            torch_nn.conv1.kernel_size[1]\n",
        "        ).tolist()\n",
        "        self.conv1_bias = torch_nn.conv1.bias.data.tolist()\n",
        "\n",
        "        self.fc1_weight = torch_nn.fc1.weight.T.data.tolist()\n",
        "        self.fc1_bias = torch_nn.fc1.bias.data.tolist()\n",
        "\n",
        "        self.fc2_weight = torch_nn.fc2.weight.T.data.tolist()\n",
        "        self.fc2_bias = torch_nn.fc2.bias.data.tolist()\n",
        "\n",
        "\n",
        "    def forward(self, enc_x, windows_nb):\n",
        "        # conv layer\n",
        "        enc_channels = []\n",
        "        for kernel, bias in zip(self.conv1_weight, self.conv1_bias):\n",
        "            y = enc_x.conv2d_im2col(kernel, windows_nb) + bias\n",
        "            enc_channels.append(y)\n",
        "        # pack all channels into a single flattened vector\n",
        "        enc_x = ts.CKKSVector.pack_vectors(enc_channels)\n",
        "        # square activation\n",
        "        enc_x.square_()\n",
        "        # fc1 layer\n",
        "        enc_x = enc_x.mm(self.fc1_weight) + self.fc1_bias\n",
        "        # square activation\n",
        "        enc_x.square_()\n",
        "        # fc2 layer\n",
        "        enc_x = enc_x.mm(self.fc2_weight) + self.fc2_bias\n",
        "        return enc_x\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)\n"
      ],
      "metadata": {
        "id": "5DVCL-IbdlgB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def enc_test(context, model, test_loader, criterion, kernel_shape, stride):\n",
        "    # initialize lists to monitor test loss and accuracy\n",
        "    test_loss = 0.0\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "    epoch = 0\n",
        "    for data, target in test_loader:\n",
        "        epoch += 1\n",
        "        # Encoding and encryption\n",
        "        x_enc, windows_nb = ts.im2col_encoding(\n",
        "            context, data.view(28, 28).tolist(), kernel_shape[0],\n",
        "            kernel_shape[1], stride\n",
        "        )\n",
        "        # Encrypted evaluation\n",
        "        enc_output = enc_model(x_enc, windows_nb)\n",
        "        # Decryption of result\n",
        "        output = enc_output.decrypt()\n",
        "        output = torch.tensor(output).view(1, -1)\n",
        "\n",
        "        # compute loss\n",
        "        loss = criterion(output, target)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # convert output probabilities to predicted class\n",
        "        _, pred = torch.max(output, 1)\n",
        "        # compare predictions to true label\n",
        "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "        # calculate test accuracy for each object class\n",
        "        label = target.data[0]\n",
        "        class_correct[label] += correct.item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "\n",
        "    # calculate and print avg test loss\n",
        "    test_loss = test_loss / sum(class_total)\n",
        "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
        "\n",
        "    for label in range(10):\n",
        "        print(\n",
        "            f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n",
        "            f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'\n",
        "        )\n",
        "\n",
        "    print(\n",
        "        f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% '\n",
        "        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "AQoC1x3HdoLy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_test_samples = int(len(test_data)  * 0.1)\n",
        "test_indices = np.random.choice(len(test_data), size=num_test_samples, replace=False)\n",
        "test_data = torch.utils.data.Subset(test_data, test_indices)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "# Load one element at a time\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
        "# required for encoding\n",
        "kernel_shape = model.conv1.kernel_size\n",
        "stride = model.conv1.stride[0]"
      ],
      "metadata": {
        "id": "cR_SYedwis7C"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Encryption Parameters\n",
        "\n",
        "# controls precision of the fractional part\n",
        "bits_scale = 26\n",
        "\n",
        "# Create TenSEAL context\n",
        "context = ts.context(\n",
        "    ts.SCHEME_TYPE.CKKS,\n",
        "    poly_modulus_degree=8192,\n",
        "    coeff_mod_bit_sizes=[31, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, 31]\n",
        ")\n",
        "\n",
        "# set the scale\n",
        "context.global_scale = pow(2, bits_scale)\n",
        "\n",
        "# galois keys are required to do ciphertext rotations\n",
        "context.generate_galois_keys()"
      ],
      "metadata": {
        "id": "W9c8xTMld04G"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_model = EncConvNet(model)"
      ],
      "metadata": {
        "id": "u_PFNKN2d550"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_test(context, enc_model, test_loader, criterion, kernel_shape, stride)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldFUhGVohr1y",
        "outputId": "0b7e4325-3815-440c-c63d-c6638d9144b6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.107580\n",
            "\n",
            "Test Accuracy of 0: 99% (102/103)\n",
            "Test Accuracy of 1: 100% (112/112)\n",
            "Test Accuracy of 2: 98% (91/92)\n",
            "Test Accuracy of 3: 100% (98/98)\n",
            "Test Accuracy of 4: 100% (107/107)\n",
            "Test Accuracy of 5: 98% (83/84)\n",
            "Test Accuracy of 6: 99% (104/105)\n",
            "Test Accuracy of 7: 95% (90/94)\n",
            "Test Accuracy of 8: 95% (101/106)\n",
            "Test Accuracy of 9: 97% (97/99)\n",
            "\n",
            "Test Accuracy (Overall): 98% (985/1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above operation takes 1 hr 37 mins for a test set of 1000 entries."
      ],
      "metadata": {
        "id": "X_1DPTyUJ782"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def predict(context, model, image, kernel_shape, stride):\n",
        "    # Encoding and encryption\n",
        "    x_enc, windows_nb = ts.im2col_encoding(\n",
        "            context, image.view(28, 28).tolist(), kernel_shape[0],\n",
        "            kernel_shape[1], stride\n",
        "        )\n",
        "\n",
        "    # Encrypted evaluation\n",
        "    enc_output = model(x_enc, windows_nb)\n",
        "    print(f'Encrypted image: {enc_output}')\n",
        "    # Decryption of result\n",
        "    output = enc_output.decrypt()\n",
        "    output = torch.tensor(output).view(1, -1)\n",
        "\n",
        "    # Obtain predicted label\n",
        "    _, pred = torch.max(output, 1)\n",
        "    return pred.item()\n",
        "\n",
        "random_image, random_label = test_data[521]\n",
        "# Convert the image to a NumPy array\n",
        "random_image_array = random_image.numpy().squeeze()\n",
        "# Display the original image using matplotlib\n",
        "plt.figure(figsize=(4, 4))\n",
        "plt.imshow(random_image_array, cmap='gray')\n",
        "plt.title(f\"Label: {random_label}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print(f'Predicted output: {predict(context, enc_model, random_image, kernel_shape, stride )}')"
      ],
      "metadata": {
        "id": "fd-3S6ZPuWtI",
        "outputId": "74fa71a7-7531-41c1-b6d1-26b027785151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encrypted image: <tenseal.tensors.ckksvector.CKKSVector object at 0x7f6f387c3a00>\n",
            "Predicted output: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2qSvctUU32C-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7NxmTSkM6-sQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}