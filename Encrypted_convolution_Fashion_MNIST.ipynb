{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Siya-9/Homomorphic-Encryption/blob/main/Encrypted_convolution_Fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mw7R_q4MacY4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(73)\n",
        "\n",
        "train_data = datasets.FashionMNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
        "full_test_data = datasets.FashionMNIST('data', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(full_test_data, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm33JWMmDCJk"
      },
      "source": [
        "Defining below a NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ir_Ay0Zdac_8"
      },
      "outputs": [],
      "source": [
        "class ConvNet(torch.nn.Module):\n",
        "    def __init__(self, hidden=64, output=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(1, 4, kernel_size=7, padding=0, stride=3)\n",
        "        self.fc1 = torch.nn.Linear(256, hidden)\n",
        "        self.fc2 = torch.nn.Linear(hidden, output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        # the model uses the square activation function\n",
        "        x = x * x\n",
        "        # flattening while keeping the batch axis\n",
        "        x = x.view(-1, 256)\n",
        "        x = self.fc1(x)\n",
        "        x = x * x\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJ2nzoXCcHFr"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, n_epochs=10):\n",
        "    # model in training mode\n",
        "    model.train()\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "\n",
        "        train_loss = 0.0\n",
        "        for data, target in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # calculate average losses\n",
        "        train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
        "\n",
        "    # model in evaluation mode\n",
        "    model.eval()\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7Hu-ZN6cJJy",
        "outputId": "438ca492-511b-4668-8dc5-71c78d94227f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.756596\n",
            "Epoch: 2 \tTraining Loss: 0.467550\n",
            "Epoch: 3 \tTraining Loss: 0.405746\n",
            "Epoch: 4 \tTraining Loss: 0.370436\n",
            "Epoch: 5 \tTraining Loss: 0.348817\n",
            "Epoch: 6 \tTraining Loss: 0.329300\n",
            "Epoch: 7 \tTraining Loss: 0.314558\n",
            "Epoch: 8 \tTraining Loss: 0.302702\n",
            "Epoch: 9 \tTraining Loss: 0.289028\n",
            "Epoch: 10 \tTraining Loss: 0.279030\n"
          ]
        }
      ],
      "source": [
        "model = ConvNet()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "model = train(model, train_loader, criterion, optimizer, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nm68FB8vKXww"
      },
      "source": [
        "The above operation takes 2 mins."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcd9qbNGdXK4",
        "outputId": "47fc0ba0-97a0-4c5a-8d79-4dde4eccb33e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.376166\n",
            "\n",
            "Test Accuracy of 0: 83% (832/1000)\n",
            "Test Accuracy of 1: 96% (964/1000)\n",
            "Test Accuracy of 2: 80% (800/1000)\n",
            "Test Accuracy of 3: 90% (909/1000)\n",
            "Test Accuracy of 4: 84% (842/1000)\n",
            "Test Accuracy of 5: 96% (967/1000)\n",
            "Test Accuracy of 6: 60% (606/1000)\n",
            "Test Accuracy of 7: 91% (913/1000)\n",
            "Test Accuracy of 8: 94% (942/1000)\n",
            "Test Accuracy of 9: 96% (964/1000)\n",
            "\n",
            "Test Accuracy (Overall): 87% (8739/10000)\n"
          ]
        }
      ],
      "source": [
        "def test(model, test_loader, criterion):\n",
        "    # initialize lists to monitor test loss and accuracy\n",
        "    test_loss = 0.0\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "\n",
        "    # model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    for data, target in test_loader:\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        test_loss += loss.item()\n",
        "        # convert output probabilities to predicted class\n",
        "        _, pred = torch.max(output, 1)\n",
        "        # compare predictions to true label\n",
        "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "        # calculate test accuracy for each object class\n",
        "        for i in range(len(target)):\n",
        "            label = target.data[i]\n",
        "            class_correct[label] += correct[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "    # calculate and print avg test loss\n",
        "    test_loss = test_loss/len(test_loader)\n",
        "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
        "\n",
        "    for label in range(10):\n",
        "        print(\n",
        "            f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n",
        "            f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'\n",
        "        )\n",
        "\n",
        "    print(\n",
        "        f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% '\n",
        "        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n",
        "    )\n",
        "\n",
        "test(model, test_loader, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J5VEl8fdrlm",
        "outputId": "d355f0eb-9914-4e2e-a9d5-ed8b2031e0f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tenseal in /usr/local/lib/python3.10/dist-packages (0.3.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install tenseal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DVCL-IbdlgB"
      },
      "outputs": [],
      "source": [
        "import tenseal as ts\n",
        "\n",
        "\n",
        "class EncConvNet:\n",
        "    def __init__(self, torch_nn):\n",
        "        self.conv1_weight = torch_nn.conv1.weight.data.view(\n",
        "            torch_nn.conv1.out_channels, torch_nn.conv1.kernel_size[0],\n",
        "            torch_nn.conv1.kernel_size[1]\n",
        "        ).tolist()\n",
        "        self.conv1_bias = torch_nn.conv1.bias.data.tolist()\n",
        "\n",
        "        self.fc1_weight = torch_nn.fc1.weight.T.data.tolist()\n",
        "        self.fc1_bias = torch_nn.fc1.bias.data.tolist()\n",
        "\n",
        "        self.fc2_weight = torch_nn.fc2.weight.T.data.tolist()\n",
        "        self.fc2_bias = torch_nn.fc2.bias.data.tolist()\n",
        "\n",
        "\n",
        "    def forward(self, enc_x, windows_nb):\n",
        "        # conv layer\n",
        "        enc_channels = []\n",
        "        for kernel, bias in zip(self.conv1_weight, self.conv1_bias):\n",
        "            y = enc_x.conv2d_im2col(kernel, windows_nb) + bias\n",
        "            enc_channels.append(y)\n",
        "        # pack all channels into a single flattened vector\n",
        "        enc_x = ts.CKKSVector.pack_vectors(enc_channels)\n",
        "        # square activation\n",
        "        enc_x.square_()\n",
        "        # fc1 layer\n",
        "        enc_x = enc_x.mm(self.fc1_weight) + self.fc1_bias\n",
        "        # square activation\n",
        "        enc_x.square_()\n",
        "        # fc2 layer\n",
        "        enc_x = enc_x.mm(self.fc2_weight) + self.fc2_bias\n",
        "        return enc_x\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQoC1x3HdoLy"
      },
      "outputs": [],
      "source": [
        "def enc_test(context, model, test_loader, criterion, kernel_shape, stride):\n",
        "    # initialize lists to monitor test loss and accuracy\n",
        "    test_loss = 0.0\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "    epoch = 0\n",
        "    for data, target in test_loader:\n",
        "        epoch += 1\n",
        "        # Encoding and encryption\n",
        "        x_enc, windows_nb = ts.im2col_encoding(\n",
        "            context, data.view(28, 28).tolist(), kernel_shape[0],\n",
        "            kernel_shape[1], stride\n",
        "        )\n",
        "        # Encrypted evaluation\n",
        "        enc_output = enc_model(x_enc, windows_nb)\n",
        "        # Decryption of result\n",
        "        output = enc_output.decrypt()\n",
        "        output = torch.tensor(output).view(1, -1)\n",
        "\n",
        "        # compute loss\n",
        "        loss = criterion(output, target)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        if(epoch % 10 == 0):\n",
        "          print(f'Test Loss at Epoch {epoch} : {test_loss}')\n",
        "        # convert output probabilities to predicted class\n",
        "        _, pred = torch.max(output, 1)\n",
        "        # compare predictions to true label\n",
        "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "        # calculate test accuracy for each object class\n",
        "        label = target.data[0]\n",
        "        class_correct[label] += correct.item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "\n",
        "    # calculate and print avg test loss\n",
        "    test_loss = test_loss / sum(class_total)\n",
        "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
        "\n",
        "    for label in range(10):\n",
        "        print(\n",
        "            f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n",
        "            f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'\n",
        "        )\n",
        "\n",
        "    print(\n",
        "        f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% '\n",
        "        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cR_SYedwis7C"
      },
      "outputs": [],
      "source": [
        "num_test_samples = int(len(full_test_data)  * 0.1)\n",
        "test_indices = np.random.choice(len(full_test_data), size=num_test_samples, replace=False)\n",
        "test_data = torch.utils.data.Subset(full_test_data, test_indices)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "# Load one element at a time\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
        "# required for encoding\n",
        "kernel_shape = model.conv1.kernel_size\n",
        "stride = model.conv1.stride[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9c8xTMld04G"
      },
      "outputs": [],
      "source": [
        "## Encryption Parameters\n",
        "\n",
        "# controls precision of the fractional part\n",
        "bits_scale = 26\n",
        "\n",
        "# Create TenSEAL context\n",
        "context = ts.context(\n",
        "    ts.SCHEME_TYPE.CKKS,\n",
        "    poly_modulus_degree=8192,\n",
        "    coeff_mod_bit_sizes=[31, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, 31]\n",
        ")\n",
        "\n",
        "# set the scale\n",
        "context.global_scale = pow(2, bits_scale)\n",
        "\n",
        "# galois keys are required to do ciphertext rotations\n",
        "context.generate_galois_keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_PFNKN2d550"
      },
      "outputs": [],
      "source": [
        "enc_model = EncConvNet(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldFUhGVohr1y",
        "outputId": "159d5fcd-959f-49be-f643-65e394aa9894"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss at Epoch 10 : 2.502538067270045\n",
            "Test Loss at Epoch 20 : 7.024592147047308\n",
            "Test Loss at Epoch 30 : 8.198403301282717\n",
            "Test Loss at Epoch 40 : 17.529122321496253\n",
            "Test Loss at Epoch 50 : 31.09989969431077\n",
            "Test Loss at Epoch 60 : 34.1097912536006\n",
            "Test Loss at Epoch 70 : 40.7770907034355\n",
            "Test Loss at Epoch 80 : 43.33655027230471\n",
            "Test Loss at Epoch 90 : 49.85656174344532\n",
            "Test Loss at Epoch 100 : 54.6404355113693\n",
            "Test Loss at Epoch 110 : 57.19311138370422\n",
            "Test Loss at Epoch 120 : 57.94069484446545\n",
            "Test Loss at Epoch 130 : 58.64019626157387\n",
            "Test Loss at Epoch 140 : 59.677766128613435\n",
            "Test Loss at Epoch 150 : 66.36593457278462\n",
            "Test Loss at Epoch 160 : 71.25957680600362\n",
            "Test Loss at Epoch 170 : 84.83598446472558\n",
            "Test Loss at Epoch 180 : 86.41253378284074\n",
            "Test Loss at Epoch 190 : 91.9383066282133\n",
            "Test Loss at Epoch 200 : 93.85716841251616\n",
            "Test Loss at Epoch 210 : 96.1216154953998\n",
            "Test Loss at Epoch 220 : 100.01362449997742\n",
            "Test Loss at Epoch 230 : 103.86362916572017\n",
            "Test Loss at Epoch 240 : 114.18398814672247\n",
            "Test Loss at Epoch 250 : 114.87139524391961\n",
            "Test Loss at Epoch 260 : 117.06555146590682\n",
            "Test Loss at Epoch 270 : 125.1466593954595\n",
            "Test Loss at Epoch 280 : 125.36092128478623\n",
            "Test Loss at Epoch 290 : 127.70003962390757\n",
            "Test Loss at Epoch 300 : 130.39863601753888\n",
            "Test Loss at Epoch 310 : 137.53544486643324\n",
            "Test Loss at Epoch 320 : 138.49436041304187\n",
            "Test Loss at Epoch 330 : 139.71635879506692\n",
            "Test Loss at Epoch 340 : 142.4266992965742\n",
            "Test Loss at Epoch 350 : 143.69719253605325\n",
            "Test Loss at Epoch 360 : 155.952391840002\n",
            "Test Loss at Epoch 370 : 160.27427157688425\n",
            "Test Loss at Epoch 380 : 174.75842177670046\n",
            "Test Loss at Epoch 390 : 181.2402807180776\n",
            "Test Loss at Epoch 400 : 181.7153365075124\n",
            "Test Loss at Epoch 410 : 183.04523179471545\n",
            "Test Loss at Epoch 420 : 185.60475771695457\n",
            "Test Loss at Epoch 430 : 193.17739474519\n",
            "Test Loss at Epoch 440 : 201.6080486217277\n",
            "Test Loss at Epoch 450 : 204.21187562626963\n",
            "Test Loss at Epoch 460 : 210.26934781717662\n",
            "Test Loss at Epoch 470 : 213.09583613746716\n",
            "Test Loss at Epoch 480 : 217.55030878886672\n",
            "Test Loss at Epoch 490 : 220.0864006175564\n",
            "Test Loss at Epoch 500 : 223.8172580760186\n",
            "Test Loss at Epoch 510 : 231.5026012150668\n",
            "Test Loss at Epoch 520 : 232.71926487552835\n",
            "Test Loss at Epoch 530 : 233.13653146604807\n",
            "Test Loss at Epoch 540 : 249.47811308231908\n",
            "Test Loss at Epoch 550 : 250.47715398375445\n",
            "Test Loss at Epoch 560 : 253.90743870585507\n",
            "Test Loss at Epoch 570 : 262.36227326776645\n",
            "Test Loss at Epoch 580 : 267.34879864507604\n",
            "Test Loss at Epoch 590 : 276.8186018879038\n",
            "Test Loss at Epoch 600 : 284.1372053946898\n",
            "Test Loss at Epoch 610 : 287.602854474143\n",
            "Test Loss at Epoch 620 : 289.91971514124907\n",
            "Test Loss at Epoch 630 : 296.7099151868499\n",
            "Test Loss at Epoch 640 : 297.34597844809514\n",
            "Test Loss at Epoch 650 : 299.3760427582191\n",
            "Test Loss at Epoch 660 : 299.82424603512834\n",
            "Test Loss at Epoch 670 : 302.1548707368164\n",
            "Test Loss at Epoch 680 : 308.62064718818493\n",
            "Test Loss at Epoch 690 : 312.31411366629965\n",
            "Test Loss at Epoch 700 : 313.7005318230669\n",
            "Test Loss at Epoch 710 : 318.44165212889897\n",
            "Test Loss at Epoch 720 : 328.0104148347911\n",
            "Test Loss at Epoch 730 : 329.57433405581895\n",
            "Test Loss at Epoch 740 : 332.42601490944406\n",
            "Test Loss at Epoch 750 : 335.65535113442064\n",
            "Test Loss at Epoch 760 : 341.5529840947526\n",
            "Test Loss at Epoch 770 : 348.8890706365152\n",
            "Test Loss at Epoch 780 : 350.6834732297809\n",
            "Test Loss at Epoch 790 : 359.13919729145135\n",
            "Test Loss at Epoch 800 : 364.41110860707056\n",
            "Test Loss at Epoch 810 : 367.1398949517245\n",
            "Test Loss at Epoch 820 : 371.62148472556896\n",
            "Test Loss at Epoch 830 : 372.03604313562187\n",
            "Test Loss at Epoch 840 : 375.72966785520634\n",
            "Test Loss at Epoch 850 : 377.0015875462525\n",
            "Test Loss at Epoch 860 : 386.68337204079967\n",
            "Test Loss at Epoch 870 : 387.53158939780985\n",
            "Test Loss at Epoch 880 : 388.74989971484354\n",
            "Test Loss at Epoch 890 : 391.0886573773827\n",
            "Test Loss at Epoch 900 : 398.17870393922055\n",
            "Test Loss at Epoch 910 : 403.32700036069434\n",
            "Test Loss at Epoch 920 : 407.1093130009739\n",
            "Test Loss at Epoch 930 : 414.30062194638987\n",
            "Test Loss at Epoch 940 : 418.942356168662\n",
            "Test Loss at Epoch 950 : 422.8974161765539\n",
            "Test Loss at Epoch 960 : 426.03157023042445\n",
            "Test Loss at Epoch 970 : 429.62104991151944\n",
            "Test Loss at Epoch 980 : 437.85726058720036\n",
            "Test Loss at Epoch 990 : 440.70568432520065\n",
            "Test Loss at Epoch 1000 : 440.99249144378825\n",
            "Test Loss: 0.440992\n",
            "\n",
            "Test Accuracy of 0: 83% (80/96)\n",
            "Test Accuracy of 1: 95% (79/83)\n",
            "Test Accuracy of 2: 77% (70/90)\n",
            "Test Accuracy of 3: 97% (102/105)\n",
            "Test Accuracy of 4: 80% (80/100)\n",
            "Test Accuracy of 5: 92% (104/112)\n",
            "Test Accuracy of 6: 66% (77/116)\n",
            "Test Accuracy of 7: 89% (90/101)\n",
            "Test Accuracy of 8: 89% (85/95)\n",
            "Test Accuracy of 9: 96% (98/102)\n",
            "\n",
            "Test Accuracy (Overall): 86% (865/1000)\n"
          ]
        }
      ],
      "source": [
        "enc_test(context, enc_model, test_loader, criterion, kernel_shape, stride)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_1DPTyUJ782"
      },
      "source": [
        "The above operation takes 1 hr 37 mins for a test set of 1000 entries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fd-3S6ZPuWtI",
        "outputId": "26608639-608d-4c4d-9cf6-1638b1ee331a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encrypted image: <tenseal.tensors.ckksvector.CKKSVector object at 0x78423aa6a7d0>\n",
            "Predicted output: 5\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def predict(context, model, image, kernel_shape, stride):\n",
        "    # Encoding and encryption\n",
        "    x_enc, windows_nb = ts.im2col_encoding(\n",
        "            context, image.view(28, 28).tolist(), kernel_shape[0],\n",
        "            kernel_shape[1], stride\n",
        "        )\n",
        "\n",
        "    # Encrypted evaluation\n",
        "    enc_output = model(x_enc, windows_nb)\n",
        "    print(f'Encrypted image: {enc_output}')\n",
        "    # Decryption of result\n",
        "    output = enc_output.decrypt()\n",
        "    output = torch.tensor(output).view(1, -1)\n",
        "\n",
        "    # Obtain predicted label\n",
        "    _, pred = torch.max(output, 1)\n",
        "    return pred.item()\n",
        "\n",
        "random_image, random_label = test_data[521]\n",
        "# Convert the image to a NumPy array\n",
        "random_image_array = random_image.numpy().squeeze()\n",
        "# Display the original image using matplotlib\n",
        "plt.figure(figsize=(4, 4))\n",
        "plt.imshow(random_image_array, cmap='gray')\n",
        "plt.title(f\"Label: {random_label}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print(f'Predicted output: {predict(context, enc_model, random_image, kernel_shape, stride )}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1zLJyhOFwynU19NA3aoj-d06A8jqrcPmT",
      "authorship_tag": "ABX9TyMEqU72tyJseurUNov7vilL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}